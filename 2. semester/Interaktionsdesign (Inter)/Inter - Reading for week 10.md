---
date: 04-03-23
day: Sat
week: 10
year: 2023
type: Reading
course: Inter
status: 
semester: 2
tags:
Summary: ""
---
##### Weekly note
[[Uge 10 - 2023]]
I denne note har jeg skrevet noter til evaluering som blev dækket i forelæsningen fra mandag og onsdag. Yderligere finder du en slags guide som du kan bruge til at skrive noget til del 2 inden vi mødes imorgen til øvelser. 
# Guide til skrivning af del 2
**Læs teori noterne først fordi jeg referer til nogle af termerne han bruger i forelæsningerne**

hvorfor tænke højt test, hvad vi man opnå

**lad vær med at skrive noget om hvilke brugbarheds problemer du opdaget under din test, vi snakker hvad vi hver så og skriver derefter problemer vi så folk havde med siden**

Du kan skrive noget om hvordan vi havde delt os op og lavet en test hver, at vi optag testene (jeg har skræmoptaget, skriv evt hvad du gjorde.) 

skriv noget om at vi undgår problematiske spørgsmål

skriv at vi har sørget for at tale med hianden og delt hvad vi hver i ser oplevet i vores test før vi analyserer.

beskriv overvejelser og styrker ved den valgte metode i forhold til at evaluerer det problem vi er blevet givet.  (har skrevet noget til pros and cons, ref til onsdags forelæsningen) \citep[slide ##]{slidesons}
# Evaluering - mandags forelæsning
Hvis man bruger eksperter til sin evaluering er det en analytisk evaluering  (eksamen er nok analystisk evaluering)

bruger man brugerne er det en emperisk analyse (tænke højt test)

**hvilke kriterer skal vi bruge til at bedømme brugbarhed? kræver en målestok for om noget har værdi:**

det kan være helt konkrette mål at man som novice skal være i stand til at kunne løse opgaven på 5 minutter. lever det op til dette mål

eller brugeroplevelses mål, et system skal opleves stimulant eller andet og her kan man bruge spørgeskemaer til at evaluerer om de gør det.

bruge kognitive retningslinjer hvor godt er de opfyldt 
![](https://i.imgur.com/YaNjUQz.png)

et anden måde at stille kriterer  med kriteret fra steve krug, dont make me think: vi skal lave systemer der ikke kræver at folk stopper op og tænker over hvordan de skal løse en opgave, det skal være intuitivt.

hvornår er anvendelsen af en evaluering god, hvad har en god metode? en god evaluering har:
- validity 
- reliable
- den er realistisk (tæt på brugerens faktiske opgaveløsning, tænke højt ville kunne være mere realistisk end en analystisk evaluering fordi man faktisk får en bruger til at finde problemer de har, modsat en ekspert som vurderer at der kunne være problemer et sted). 

Er den overbevisende, bliver problemer som man finder i evaluering taget seriøst så de faktisk bliver løst. tænke højt er overbevisende fordi hvis man ser en video af en bruger der faktisk kæmper med et system, så er det svært at modsige at der er problemer. 

det skal være gyldigt: anvendelsen af metoden skal give indsigt af hvordan systemet opfattes af virkelige mennekser og deres brugbarheds problemer er virkelige ellers spilder vi vores tid på at rette problemer der ikke eksisterer. Hvis vi laver evalueringen igen skal vi gerne se de samme problemer. 

## evaluerings formål
en evalueringer kan være summative og formative 

afleveringensopgaven  vi afleverer "hver" uge er formativ fordi den former senere opgaver med feedback

inter eksamen er summativ fordi den evalulerer og giver en karakter, men ikke feedback på hvorfor vi fik den karakter. 

![](https://i.imgur.com/cruxZub.png)
![](https://i.imgur.com/QAM50Ou.png)
man skal kunne se hvilke tilstand systemet er i:
f.eks. hvis at man har trykket caps lock 
hvis der er en lang pause efter en interaktion giver det mening at hvis et loading ikon
![](https://i.imgur.com/jHWFKBH.png)
# Tænke højt test - onsdags forelæsning
brugerene snakker om hvad de tænker imens de løser en opgave(r)

**formålet med en tænke højt test er at kigge efter brugbarshedsproblemer, når de bliver identificeret kan vi fjerne dem og gøre brugbarheden ved systemet bedre*

vil gerne give en nem opgave til at starte med så de kan lære at tænke højt. vi vil også gerne have det er nemt at forstå hvornår opgaven er løst, det skal være en opgave hvor man nemt kan se at man har løst opgaven. lad brugeren vurderer om opgaven er løst og gør det tydeligt hvornår den er løst. 

lad det være klart for brugeren hvad de er med til, foreklar hvad en tænke højt test går ud på. Det er måske unatrutligt for nogle at skulle tænke højt, så vi vil gerne forklare hvad testen går ud på (ikke foreklare opgaver, men bare forklare ideen med en tænke højt test)

![](https://i.imgur.com/igvTBMJ.png)

**vi vil gerne have en test der er gyldig og valid Derfor:** 
opgaver skal ikke have skjult hjælp, ikke have ord som er indeholdt i opgaven ikke lav en opgave:  "giv et sticker donation" på en side hvor der er en knap "giv en sticker donation", istedet "giv et bidrag til siden". Opgave beskrivelsen skal altså forsøge ikke at inkludere hjælp til at løse opgaven.

En tænke højt test er:
![|200](https://i.imgur.com/dpKviNT.png)

## Metoder til tænkehøjt test
### Pure think aloud: 
kun siger keep talking, man stiller altså ikke spørgsmål undervejs, man lader bare brugeren svømme selv og finde ud af at løse problemet, det er altså det modsatte af molichs advices til tænke højttests. Hornbæk kan godt lide denne metode uden spørgsmål fordi man ikke risikerer at guide og løse opgaven for brugeren. 


### Morlichs advice for think out loud
vi vil helst ikke gøre dette
![](https://i.imgur.com/bLYy1Tk.png)

### not a interview
det er ikke et interview, de tænker og verbaliserer hvad de gør. man skal altså ikke komme ind i et interview hvor man begynder at stille sprøgsmål. 

interview spørgsmål kan gøres efter tænke højt, det kunne være en afslutning, såsom "ville du bruge dette system", det skal først gøres når man er færdigt med tænke højt test evt. 

**spørgsmål under session kan være problematiske:**
- tror du at du ville gå tilbage til forsiden?
- hvad foventet du at se?
- ville du gøre dette på en anden måde?
de er problematiske, det er ikke formålet med tænke højt. det er spekulative spørgsmål og bør ikke stilles under en tænke højt test. 
## hvad kigger vi på i tænke højt test
husk tilbage på usability modelen fra jakob nielsen, fem indikatorrer på usability.
easy to learn 
efficent to use 
easy to remember 
few errors 
subjectivly pleasing 
![[Pasted image 20230312183245.png]]
er der ting i systemet hvor de her de her 5 aspekter ikke bliver opfyldt: disse kan kaldes brugbarhedsproblemer(altså hvor de ikke opfylder en af de 5 aspekter). er der ting der irriterer eller forstyrre brugeren. Dem vil vi gerne identificere. Det er målet med en tænkehøjt test.
![](https://i.imgur.com/6OsB3zX.png)
![](https://i.imgur.com/EHfGEmm.png)
bliver brugeren overrasket? husk: dont make me think

der er et mismatch med hvad folk forventer der vil ske og hvad der sker. 

## analyse af tænkehøjt test
problembeskrivelser kan bruges til at få tænkt over hvad problemet betyder for systemet

problemer hentyder til brugbarhedsproblemer
![](https://i.imgur.com/WvFhvVj.png)

Dette vil vi først gøre når vi er samlet:
![](https://i.imgur.com/A8h3BP4.png)
vi skal snakke sammen efter evaluering og snakke om hvad vi har set i vores tests

utitlity overvejelser er super nøddige 
vi bør lægge mærke til om brugeren siger de kan lide systemet eller ej. 
vi må gerne rapporterer hvis folk kan lide systemet eller ej. 
![](https://i.imgur.com/7uqG0D9.png)

enkelt mest nyttige teknik i interaktions design til at gøre systemer mere brugbare. 
## pros og cons ved tænke højt test:
### pros:
 
de er billige, man behøver en bruger men ikke meget udstyr, de er overbevisende, man er mere tilbøjelig til at tro på at der er et problem hvis man ser nogen have et problem med systemet. 

de er realistiske, man ser rigtige brugeres problemer ikke hvad en ekspert har vurderet er et problem. 

### cons:
![](https://i.imgur.com/EGoMhqk.png)
det kan være unaturligt og mærkeligt at skulle tænke højt 

nogen problemer findes her kun af 2 ud af 19 evalutorer
![](https://i.imgur.com/0LfKmJI.png)
# Generelt om emperiske evalutations metoder
![](https://i.imgur.com/3xtwkxI.png)
